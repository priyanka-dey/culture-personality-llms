{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HUGGING_FACE_API_KEY\"] = os.getenv(\"HUGGING_FACE_API_KEY\")\n",
    "os.environ[\"OPEN_AI_API\"] = os.getenv(\"OPEN_AI_API\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv('GROQ_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "open_ai_api_key = os.getenv(\"OPEN_AI_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = \".\\Documents\"\n",
    "documents = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n",
      "XRef object at 2945 can not be read, some object may be missing\n",
      "XRef object at 2945 can not be read, some object may be missing\n",
      "Ignoring wrong pointing object 2268 0 (offset 1064028)\n",
      "Ignoring wrong pointing object 2269 0 (offset 1064028)\n"
     ]
    }
   ],
   "source": [
    "for folder, _, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder, file)\n",
    "        try:\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            docs = loader.load()\n",
    "            documents.extend(docs)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents into manageable chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=200)\n",
    "chunked_documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 2702/2702 [00:00<00:00, 6380.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents, desc=\"Splitting Documents\"):\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "    chunked_documents.extend(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=open_ai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = FAISS.from_documents(chunked_documents, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model='llama-3.2-3b-preview', groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory setup\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # Key used to store conversation history\n",
    "    return_messages=True        # Allows memory to be added to chain responses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversational Retrieval Chain\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5}),\n",
    "    memory=memory,\n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Functions to generate cultural norms and scenarios\n",
    "# def generate_cultural_norms(country: str) -> dict:\n",
    "#     prompt = f\"Provide me 10 unique sentences highlighting the core values/important aspects of individuals living in {country}.\"\n",
    "#     response = qa_chain.run(prompt)\n",
    "#     norms = [\n",
    "#         {\"id\": idx + 1, \"text\": norm.strip()}\n",
    "#         for idx, norm in enumerate(response.split(\"\\n\"))\n",
    "#     ]\n",
    "#     return {\n",
    "#         \"gpt4-o prompt\": prompt,\n",
    "#         \"country\": country,\n",
    "#         \"norms\": norms\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cultural_norms(country: str) -> dict:\n",
    "    prompt = f\"Provide me 10 unique sentences highlighting the core values/important aspects of individuals living in {country}.\"\n",
    "    response = qa_chain.run(prompt)\n",
    "    print(response)\n",
    "    # Split the response into lines and filter undesired content\n",
    "    norms = []\n",
    "    for idx, line in enumerate(response.split(\"\\n\")):\n",
    "        line = line.strip()\n",
    "        # Check if the line is valid (e.g., non-empty and not generic text)\n",
    "        if line and not line.lower().startswith(\"i don't know\") and not \"here are\" in line.lower():\n",
    "            # Optionally, check for a pattern (e.g., starting with a number or bullet)\n",
    "            if line[0].isdigit() or line.startswith(\"-\"):\n",
    "                norms.append({\"id\": len(norms) + 1, \"text\": line})\n",
    "    \n",
    "    # If no valid norms are found, return an empty list\n",
    "    if not norms:\n",
    "        print(f\"No valid norms generated for {country}.\")\n",
    "        return {\"gpt4-o prompt\": prompt, \"country\": country, \"norms\": []}\n",
    "    \n",
    "    return {\n",
    "        \"gpt4-o prompt\": prompt,\n",
    "        \"country\": country,\n",
    "        \"norms\": norms\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_cultural_scenarios(country: str, norms: list) -> list:\n",
    "#     scenarios = []\n",
    "#     scenario_id = 1\n",
    "#     for norm in norms:\n",
    "#         prompt = (\n",
    "#             f\"I would like to generate some example scenarios showing this cultural norm in {country}. \"\n",
    "#             \"Please generate 10 scenarios, detailing each scenario with up to 2 sentences. \"\n",
    "#             \"Please refrain from stating the cultural norm in the scenario.\"\n",
    "#         )\n",
    "#         response = qa_chain.run(prompt)\n",
    "#         generated_scenarios = [\n",
    "#             {\"id\": scenario_id + idx, \"norm-id\": norm['id'], \"text\": scenario.strip()}\n",
    "#             for idx, scenario in enumerate(response.split(\"\\n\"))\n",
    "#         ]\n",
    "#         scenarios.extend(generated_scenarios)\n",
    "#         scenario_id += len(generated_scenarios)\n",
    "#     return scenarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cultural_scenarios(country: str, norms: list, batch_size: int = 3) -> list:\n",
    "    scenarios_list = []\n",
    "    scenario_id = 1\n",
    "\n",
    "    for i in range(0, len(norms), batch_size):\n",
    "        batch = norms[i:i + batch_size]\n",
    "\n",
    "        for norm in batch:\n",
    "            # Construct the prompt for each norm\n",
    "            prompt = (\n",
    "                f\"I would like to generate some example scenarios showing these cultural norms in {country}:\\n\"\n",
    "                + \"\\nPlease generate 10 scenarios for each norm, detailing each scenario with up to 2 sentences. \"\n",
    "                \"Please refrain from stating the cultural norm in the scenario.\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                # Run the prompt and handle API response\n",
    "                response = qa_chain.run(prompt)\n",
    "\n",
    "                # Process response: Split into lines and filter relevant content\n",
    "                scenario_lines = [\n",
    "                    line.strip()\n",
    "                    for line in response.split(\"\\n\")\n",
    "                    if line.strip() and not line.startswith(\"Here are\") and not line.startswith(\"**\")\n",
    "                ]\n",
    "\n",
    "                # Structure scenarios for the given norm\n",
    "                structured_scenarios = {\n",
    "                    \"gpt4-o prompt\": prompt,\n",
    "                    \"country\": country,\n",
    "                    \"scenarios\": [\n",
    "                        {\n",
    "                            \"id\": scenario_id + idx,\n",
    "                            \"norm-id\": norm['id'],\n",
    "                            \"text\": scenario\n",
    "                        }\n",
    "                        for idx, scenario in enumerate(scenario_lines[:10], start=1)\n",
    "                    ]\n",
    "                }\n",
    "\n",
    "                # Append to the list\n",
    "                scenarios_list.append(structured_scenarios)\n",
    "                scenario_id += 10\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating scenarios for norm '{norm['text']}': {e}\")\n",
    "                continue\n",
    "\n",
    "    return scenarios_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save or append to JSON file\n",
    "def save_to_json(data: dict, filename: str):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            existing_data = json.load(f)\n",
    "        if \"cultural-norms\" in data:\n",
    "            existing_data.setdefault(\"cultural-norms\", []).extend(data[\"cultural-norms\"])\n",
    "        if \"cultural_scenarios\" in data:\n",
    "            existing_data.setdefault(\"cultural_scenarios\", []).extend(data[\"cultural_scenarios\"])\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(existing_data, f, indent=4, ensure_ascii=False)\n",
    "    else:\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the core values and important aspects of individuals living in Japan can be summarized as follows:\n",
      "\n",
      "1. **Harmony (Wa)**: The concept of harmony is deeply ingrained in Japanese culture. It refers to the idea of living in balance and harmony with others, and with nature. This value is considered essential for maintaining social cohesion and stability.\n",
      "2. **Individualism/Collectivism**: Japanese individuals prioritize both individuality and collectivism. They value personal autonomy and self-expression, but also prioritize the well-being of the group and the community.\n",
      "3. **Confucianism**: Confucianism plays a significant role in shaping Japanese values and behavior. It emphasizes the importance of social hierarchy, respect for authority, and self-cultivation.\n",
      "4. **Respect for tradition**: Japanese individuals place a high value on tradition and respect for the past. This is reflected in their cultural practices, customs, and social norms.\n",
      "5. **Social cohesion**: Japan is a collectivist society, and individuals prioritize maintaining social harmony and relationships with others.\n",
      "6. **Self-cultivation**: Japanese individuals value self-cultivation and personal growth, which is reflected in their emphasis on education, discipline, and self-reflection.\n",
      "7. **Group-oriented behavior**: Japanese individuals are often group-oriented, prioritizing the needs of the group over individual interests.\n",
      "8. **Hierarchy and social status**: Japan has a hierarchical society, and individuals are aware of their social status and position within the social hierarchy.\n",
      "9. **Nature and the environment**: Japanese individuals have a deep respect for nature and the environment, reflecting their cultural values and spiritual traditions.\n",
      "\n",
      "These core values and aspects of individuals living in Japan are deeply intertwined and shape their behavior, social norms, and cultural practices. They prioritize harmony, respect for tradition, social cohesion, and self-cultivation, while also acknowledging individuality and collectivism.\n",
      "Cultural norms and scenarios for Japan saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    country = input(\"Enter the country for which to generate cultural norms and scenarios: \").strip()\n",
    "\n",
    "    # Generate cultural norms\n",
    "    cultural_norms = generate_cultural_norms(country)\n",
    "    save_to_json({\"cultural-norms\": [cultural_norms]}, \"rag_cultural_norms.json\")\n",
    "\n",
    "    # # Generate cultural scenarios\n",
    "    # cultural_scenarios = generate_cultural_scenarios(country, cultural_norms['norms'])\n",
    "    # save_to_json({\"cultural_scenarios\": cultural_scenarios}, \"rag_cultural_scenarios.json\")\n",
    "\n",
    "    print(f\"Cultural norms and scenarios for {country} saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chatbot(user_input: str) -> str:\n",
    "#     \"\"\"\n",
    "#     This function takes user input and returns the chatbot's response,\n",
    "#     retaining conversation context.\n",
    "#     \"\"\"\n",
    "#     response = qa_chain.run(user_input)\n",
    "#     return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main execution loop for the chatbot\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"Chatbot is running. Type 'exit' to end the conversation.\")\n",
    "#     while True:\n",
    "#         user_input = input(\"You: \")\n",
    "#         if user_input.lower() == \"exit\":\n",
    "#             print(\"Chatbot: Goodbye!\")\n",
    "#             break\n",
    "#         response = chatbot(user_input)\n",
    "#         print(f\"Chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
